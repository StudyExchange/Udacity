{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train-Predict\n",
    "\n",
    "**Result:**\n",
    "- Kaggle score: \n",
    "\n",
    "**Tensorboard**\n",
    "- Input at command: tensorboard --logdir=./log\n",
    "- Input at browser: http://127.0.0.1:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_name: Dog_Breed_Identification_Train-Predict_20171111_230804\n",
      "log_path: \tE:\\Udacity\\MachineLearning(Advanced)\\p6_graduation_project\\log\n",
      "model_path: \tE:\\Udacity\\MachineLearning(Advanced)\\p6_graduation_project\\model\n",
      "output_path: \tE:\\Udacity\\MachineLearning(Advanced)\\p6_graduation_project\\output\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "project_name = 'Dog_Breed_Identification'\n",
    "step_name = 'Train-Predict'\n",
    "time_str = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "run_name = project_name + '_' + step_name + '_' + time_str\n",
    "print('run_name: ' + run_name)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "log_path = os.path.join(cwd, 'log')\n",
    "model_path = os.path.join(cwd, 'model')\n",
    "output_path = os.path.join(cwd, 'output')\n",
    "print('log_path: \\t' + log_path)\n",
    "print('model_path: \\t' + model_path)\n",
    "print('output_path: \\t' + output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lables amount: 10222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(cwd, 'input', 'labels.csv'))\n",
    "print('lables amount: %d' %len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9710, 7168)\n",
      "(7168,)\n",
      "9710\n",
      "(9710, 7168)\n",
      "512\n",
      "(10357, 7168)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "x_train = []\n",
    "y_train = {}\n",
    "x_val = []\n",
    "y_val = {}\n",
    "x_test = []\n",
    "\n",
    "cwd = os.getcwd()\n",
    "feature_cgg16 = os.path.join(cwd, 'model', 'feature_VGG16_{}.h5'.format(20171105))\n",
    "feature_cgg19 = os.path.join(cwd, 'model', 'feature_VGG19_{}.h5'.format(20171105))\n",
    "feature_resnet50 = os.path.join(cwd, 'model', 'feature_ResNet50_{}.h5'.format(20171105))\n",
    "feature_xception = os.path.join(cwd, 'model', 'feature_Xception_{}.h5'.format(20171105))\n",
    "feature_inception = os.path.join(cwd, 'model', 'feature_InceptionV3_{}.h5'.format(20171105))\n",
    "# feature_inceptionResNetV2 = os.path.join(cwd, 'model', 'feature_InceptionResNetV2_{}.h5'.format(20171028))\n",
    "for filename in [feature_cgg16, feature_cgg19, feature_resnet50, feature_xception, feature_inception]:\n",
    "# for filename in [feature_inception]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        x_train.append(np.array(h['train']))\n",
    "        y_train = np.array(h['train_labels'])\n",
    "        x_val.append(np.array(h['val']))\n",
    "        y_val = np.array(h['val_labels'])\n",
    "        x_test.append(np.array(h['test']))\n",
    "\n",
    "# print(x_train[0].shape)\n",
    "x_train = np.concatenate(x_train, axis=-1)\n",
    "# y_train = np.concatenate(y_train, axis=0)\n",
    "x_val = np.concatenate(x_val, axis=-1)\n",
    "# y_val = np.concatenate(y_val, axis=0)\n",
    "x_test = np.concatenate(x_test, axis=-1)\n",
    "print(x_train.shape)\n",
    "print(x_train.shape[1:])\n",
    "\n",
    "print(len(y_train))\n",
    "print(x_val.shape)\n",
    "print(len(y_val))\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "(x_train, y_train) = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9224, 7168)\n",
      "(9224,)\n",
      "(486, 7168)\n",
      "(486,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.05, random_state=5)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9224, 120)\n",
      "(486, 120)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir:E:\\Udacity\\MachineLearning(Advanced)\\p6_graduation_project\\log\\Dog_Breed_Identification_Train-Predict_20171111_230804\n"
     ]
    }
   ],
   "source": [
    "def get_lr(x):\n",
    "    lr = round(1e-4 * 0.98 ** x, 6)\n",
    "    if lr < 5e-5:\n",
    "        lr = 5e-5\n",
    "    print(lr, end='  ')\n",
    "    return lr\n",
    "\n",
    "# annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)\n",
    "annealer = LearningRateScheduler(get_lr)\n",
    "\n",
    "log_dir = os.path.join(log_path, run_name)\n",
    "print('log_dir:' + log_dir)\n",
    "tensorBoard = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8196, input_shape=x_train.shape[1:]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8196, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8196, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9224 samples, validate on 486 samples\n",
      "0.0001  Epoch 1/200\n",
      "9224/9224 [==============================] - 3s - loss: 5.0165 - acc: 0.0081 - val_loss: 4.7593 - val_acc: 0.0062\n",
      "9.8e-05  Epoch 2/200\n",
      "9224/9224 [==============================] - 3s - loss: 4.8245 - acc: 0.0138 - val_loss: 4.7012 - val_acc: 0.0226\n",
      "9.6e-05  Epoch 3/200\n",
      "9224/9224 [==============================] - 3s - loss: 4.7552 - acc: 0.0159 - val_loss: 4.6461 - val_acc: 0.0123\n",
      "9.4e-05  Epoch 4/200\n",
      "9224/9224 [==============================] - 3s - loss: 4.6943 - acc: 0.0217 - val_loss: 4.5740 - val_acc: 0.0391\n",
      "9.2e-05  Epoch 5/200\n",
      "9224/9224 [==============================] - 3s - loss: 4.6106 - acc: 0.0334 - val_loss: 4.4513 - val_acc: 0.1008\n",
      "9e-05  Epoch 6/200\n",
      "9224/9224 [==============================] - 3s - loss: 4.5023 - acc: 0.0461 - val_loss: 4.3099 - val_acc: 0.0864\n",
      "8.9e-05  Epoch 7/200\n",
      "9224/9224 [==============================] - 3s - loss: 4.3842 - acc: 0.0540 - val_loss: 4.1556 - val_acc: 0.0905\n",
      "8.7e-05  Epoch 8/200\n",
      "9224/9224 [==============================] - 3s - loss: 4.2554 - acc: 0.0642 - val_loss: 4.0205 - val_acc: 0.0967\n",
      "8.5e-05  Epoch 9/200\n",
      "9224/9224 [==============================] - 3s - loss: 4.1225 - acc: 0.0812 - val_loss: 3.8677 - val_acc: 0.1461\n",
      "8.3e-05  Epoch 10/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.9888 - acc: 0.0979 - val_loss: 3.6997 - val_acc: 0.1481\n",
      "8.2e-05  Epoch 11/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.8496 - acc: 0.1117 - val_loss: 3.5692 - val_acc: 0.1934\n",
      "8e-05  Epoch 12/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.7267 - acc: 0.1291 - val_loss: 3.4326 - val_acc: 0.2037\n",
      "7.8e-05  Epoch 13/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.6213 - acc: 0.1480 - val_loss: 3.3340 - val_acc: 0.2078\n",
      "7.7e-05  Epoch 14/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.5075 - acc: 0.1580 - val_loss: 3.2004 - val_acc: 0.2469\n",
      "7.5e-05  Epoch 15/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.4006 - acc: 0.1771 - val_loss: 3.0885 - val_acc: 0.2922\n",
      "7.4e-05  Epoch 16/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.2993 - acc: 0.1928 - val_loss: 2.9916 - val_acc: 0.2963\n",
      "7.2e-05  Epoch 17/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.2068 - acc: 0.2087 - val_loss: 2.9149 - val_acc: 0.2881\n",
      "7.1e-05  Epoch 18/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.1274 - acc: 0.2278 - val_loss: 2.8211 - val_acc: 0.3251\n",
      "7e-05  Epoch 19/200\n",
      "9224/9224 [==============================] - 3s - loss: 3.0477 - acc: 0.2483 - val_loss: 2.7481 - val_acc: 0.3436\n",
      "6.8e-05  Epoch 20/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.9613 - acc: 0.2520 - val_loss: 2.6715 - val_acc: 0.3313\n",
      "6.7e-05  Epoch 21/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.8930 - acc: 0.2665 - val_loss: 2.5988 - val_acc: 0.3868\n",
      "6.5e-05  Epoch 22/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.8383 - acc: 0.2729 - val_loss: 2.5241 - val_acc: 0.4177\n",
      "6.4e-05  Epoch 23/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.7701 - acc: 0.2913 - val_loss: 2.4496 - val_acc: 0.4095\n",
      "6.3e-05  Epoch 24/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.6941 - acc: 0.3139 - val_loss: 2.3865 - val_acc: 0.4733\n",
      "6.2e-05  Epoch 25/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.6352 - acc: 0.3313 - val_loss: 2.3404 - val_acc: 0.4691\n",
      "6e-05  Epoch 26/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.5786 - acc: 0.3324 - val_loss: 2.3008 - val_acc: 0.4774\n",
      "5.9e-05  Epoch 27/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.5045 - acc: 0.3549 - val_loss: 2.2178 - val_acc: 0.5082\n",
      "5.8e-05  Epoch 28/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.4763 - acc: 0.3570 - val_loss: 2.1686 - val_acc: 0.4938\n",
      "5.7e-05  Epoch 29/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.4166 - acc: 0.3720 - val_loss: 2.1256 - val_acc: 0.5082\n",
      "5.6e-05  Epoch 30/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.3636 - acc: 0.3832 - val_loss: 2.0840 - val_acc: 0.5062\n",
      "5.5e-05  Epoch 31/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.3205 - acc: 0.3948 - val_loss: 2.0312 - val_acc: 0.5350\n",
      "5.3e-05  Epoch 32/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.2718 - acc: 0.4052 - val_loss: 2.0012 - val_acc: 0.5144\n",
      "5.2e-05  Epoch 33/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.2265 - acc: 0.4144 - val_loss: 1.9461 - val_acc: 0.5617\n",
      "5.1e-05  Epoch 34/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.1911 - acc: 0.4310 - val_loss: 1.9053 - val_acc: 0.5679\n",
      "5e-05  Epoch 35/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.1483 - acc: 0.4408 - val_loss: 1.8845 - val_acc: 0.5535\n",
      "5e-05  Epoch 36/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.1196 - acc: 0.4467 - val_loss: 1.8612 - val_acc: 0.5679\n",
      "5e-05  Epoch 37/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.0753 - acc: 0.4629 - val_loss: 1.8362 - val_acc: 0.5947\n",
      "5e-05  Epoch 38/200\n",
      "9224/9224 [==============================] - 3s - loss: 2.0429 - acc: 0.4732 - val_loss: 1.7999 - val_acc: 0.5782\n",
      "5e-05  Epoch 39/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.9986 - acc: 0.4831 - val_loss: 1.7709 - val_acc: 0.5823\n",
      "5e-05  Epoch 40/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.9609 - acc: 0.4907 - val_loss: 1.7436 - val_acc: 0.5823\n",
      "5e-05  Epoch 41/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.9350 - acc: 0.4971 - val_loss: 1.6918 - val_acc: 0.6029\n",
      "5e-05  Epoch 42/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.9009 - acc: 0.5041 - val_loss: 1.6575 - val_acc: 0.6152\n",
      "5e-05  Epoch 43/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.8651 - acc: 0.5215 - val_loss: 1.6441 - val_acc: 0.6111\n",
      "5e-05  Epoch 44/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.8343 - acc: 0.5168 - val_loss: 1.6071 - val_acc: 0.6214\n",
      "5e-05  Epoch 45/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.8169 - acc: 0.5236 - val_loss: 1.5864 - val_acc: 0.6193\n",
      "5e-05  Epoch 46/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.7877 - acc: 0.5331 - val_loss: 1.5650 - val_acc: 0.6255\n",
      "5e-05  Epoch 47/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.7460 - acc: 0.5506 - val_loss: 1.5373 - val_acc: 0.6337\n",
      "5e-05  Epoch 48/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.7166 - acc: 0.5534 - val_loss: 1.5240 - val_acc: 0.6461\n",
      "5e-05  Epoch 49/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.6916 - acc: 0.5605 - val_loss: 1.4918 - val_acc: 0.6543\n",
      "5e-05  Epoch 50/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.6580 - acc: 0.5711 - val_loss: 1.4568 - val_acc: 0.6543\n",
      "5e-05  Epoch 51/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.6243 - acc: 0.5810 - val_loss: 1.4382 - val_acc: 0.6379\n",
      "5e-05  Epoch 52/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.6073 - acc: 0.5889 - val_loss: 1.4210 - val_acc: 0.6420\n",
      "5e-05  Epoch 53/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.5772 - acc: 0.5917 - val_loss: 1.4088 - val_acc: 0.6646\n",
      "5e-05  Epoch 54/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.5592 - acc: 0.5976 - val_loss: 1.3842 - val_acc: 0.6646\n",
      "5e-05  Epoch 55/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.5361 - acc: 0.5988 - val_loss: 1.3535 - val_acc: 0.6728\n",
      "5e-05  Epoch 56/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.5013 - acc: 0.6183 - val_loss: 1.3447 - val_acc: 0.6770\n",
      "5e-05  Epoch 57/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.4831 - acc: 0.6221 - val_loss: 1.3101 - val_acc: 0.6852\n",
      "5e-05  Epoch 58/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.4430 - acc: 0.6361 - val_loss: 1.2776 - val_acc: 0.6975\n",
      "5e-05  Epoch 59/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.4279 - acc: 0.6392 - val_loss: 1.2630 - val_acc: 0.6934\n",
      "5e-05  Epoch 60/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.4249 - acc: 0.6309 - val_loss: 1.2453 - val_acc: 0.7037\n",
      "5e-05  Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224/9224 [==============================] - 3s - loss: 1.3926 - acc: 0.6587 - val_loss: 1.2332 - val_acc: 0.7058\n",
      "5e-05  Epoch 62/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.3738 - acc: 0.6599 - val_loss: 1.2308 - val_acc: 0.6955\n",
      "5e-05  Epoch 63/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.3648 - acc: 0.6512 - val_loss: 1.1950 - val_acc: 0.6975\n",
      "5e-05  Epoch 64/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.3314 - acc: 0.6660 - val_loss: 1.1892 - val_acc: 0.7202\n",
      "5e-05  Epoch 65/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.3114 - acc: 0.6671 - val_loss: 1.1678 - val_acc: 0.7263\n",
      "5e-05  Epoch 66/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.2942 - acc: 0.6773 - val_loss: 1.1536 - val_acc: 0.7325\n",
      "5e-05  Epoch 67/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.2773 - acc: 0.6751 - val_loss: 1.1282 - val_acc: 0.7387\n",
      "5e-05  Epoch 68/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.2446 - acc: 0.6919 - val_loss: 1.1342 - val_acc: 0.7305\n",
      "5e-05  Epoch 69/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.2556 - acc: 0.6776 - val_loss: 1.0987 - val_acc: 0.7243\n",
      "5e-05  Epoch 70/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.2095 - acc: 0.7016 - val_loss: 1.0872 - val_acc: 0.7202\n",
      "5e-05  Epoch 71/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.2028 - acc: 0.6981 - val_loss: 1.0914 - val_acc: 0.7346\n",
      "5e-05  Epoch 72/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.1792 - acc: 0.7059 - val_loss: 1.0654 - val_acc: 0.7305\n",
      "5e-05  Epoch 73/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.1527 - acc: 0.7116 - val_loss: 1.0598 - val_acc: 0.7407\n",
      "5e-05  Epoch 74/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.1566 - acc: 0.7132 - val_loss: 1.0579 - val_acc: 0.7551\n",
      "5e-05  Epoch 75/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.1378 - acc: 0.7221 - val_loss: 1.0414 - val_acc: 0.7531\n",
      "5e-05  Epoch 76/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.1234 - acc: 0.7259 - val_loss: 1.0211 - val_acc: 0.7551\n",
      "5e-05  Epoch 77/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.1078 - acc: 0.7231 - val_loss: 1.0231 - val_acc: 0.7551\n",
      "5e-05  Epoch 78/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.0879 - acc: 0.7327 - val_loss: 1.0150 - val_acc: 0.7510\n",
      "5e-05  Epoch 79/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.0673 - acc: 0.7400 - val_loss: 0.9670 - val_acc: 0.7695\n",
      "5e-05  Epoch 80/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.0582 - acc: 0.7380 - val_loss: 0.9809 - val_acc: 0.7675\n",
      "5e-05  Epoch 81/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.0312 - acc: 0.7480 - val_loss: 0.9471 - val_acc: 0.7757\n",
      "5e-05  Epoch 82/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.0226 - acc: 0.7557 - val_loss: 0.9589 - val_acc: 0.7634\n",
      "5e-05  Epoch 83/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.0227 - acc: 0.7501 - val_loss: 0.9323 - val_acc: 0.7798\n",
      "5e-05  Epoch 84/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.0169 - acc: 0.7503 - val_loss: 0.9208 - val_acc: 0.7819\n",
      "5e-05  Epoch 85/200\n",
      "9224/9224 [==============================] - 3s - loss: 1.0121 - acc: 0.7502 - val_loss: 0.9396 - val_acc: 0.7613\n",
      "5e-05  Epoch 86/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.9697 - acc: 0.7669 - val_loss: 0.9010 - val_acc: 0.7840\n",
      "5e-05  Epoch 87/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.9532 - acc: 0.7683 - val_loss: 0.8920 - val_acc: 0.7757\n",
      "5e-05  Epoch 88/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.9620 - acc: 0.7682 - val_loss: 0.8847 - val_acc: 0.7737\n",
      "5e-05  Epoch 89/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.9338 - acc: 0.7698 - val_loss: 0.9271 - val_acc: 0.7593\n",
      "5e-05  Epoch 90/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.9586 - acc: 0.7605 - val_loss: 0.8610 - val_acc: 0.7840\n",
      "5e-05  Epoch 91/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.9354 - acc: 0.7686 - val_loss: 0.8676 - val_acc: 0.7819\n",
      "5e-05  Epoch 92/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.9058 - acc: 0.7786 - val_loss: 0.8683 - val_acc: 0.7593\n",
      "5e-05  Epoch 93/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8798 - acc: 0.7895 - val_loss: 0.8582 - val_acc: 0.7675\n",
      "5e-05  Epoch 94/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8749 - acc: 0.7885 - val_loss: 0.8418 - val_acc: 0.7675\n",
      "5e-05  Epoch 95/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8712 - acc: 0.7821 - val_loss: 0.8568 - val_acc: 0.7737\n",
      "5e-05  Epoch 96/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8711 - acc: 0.7903 - val_loss: 0.8375 - val_acc: 0.7778\n",
      "5e-05  Epoch 97/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8474 - acc: 0.7979 - val_loss: 0.8111 - val_acc: 0.7819\n",
      "5e-05  Epoch 98/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8277 - acc: 0.8032 - val_loss: 0.8091 - val_acc: 0.7798\n",
      "5e-05  Epoch 99/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8405 - acc: 0.7941 - val_loss: 0.8361 - val_acc: 0.7757\n",
      "5e-05  Epoch 100/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8292 - acc: 0.7985 - val_loss: 0.8003 - val_acc: 0.7778\n",
      "5e-05  Epoch 101/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8120 - acc: 0.8034 - val_loss: 0.7951 - val_acc: 0.7819\n",
      "5e-05  Epoch 102/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7985 - acc: 0.8046 - val_loss: 0.7839 - val_acc: 0.7901\n",
      "5e-05  Epoch 103/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.8000 - acc: 0.8056 - val_loss: 0.7864 - val_acc: 0.7984\n",
      "5e-05  Epoch 104/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7754 - acc: 0.8113 - val_loss: 0.7641 - val_acc: 0.7984\n",
      "5e-05  Epoch 105/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7824 - acc: 0.8120 - val_loss: 0.7831 - val_acc: 0.7901\n",
      "5e-05  Epoch 106/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7811 - acc: 0.8103 - val_loss: 0.7699 - val_acc: 0.7922\n",
      "5e-05  Epoch 107/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7668 - acc: 0.8133 - val_loss: 0.7598 - val_acc: 0.7942\n",
      "5e-05  Epoch 108/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7411 - acc: 0.8209 - val_loss: 0.7472 - val_acc: 0.7922\n",
      "5e-05  Epoch 109/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7500 - acc: 0.8184 - val_loss: 0.7657 - val_acc: 0.7901\n",
      "5e-05  Epoch 110/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7318 - acc: 0.8207 - val_loss: 0.7350 - val_acc: 0.8045\n",
      "5e-05  Epoch 111/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7180 - acc: 0.8325 - val_loss: 0.7164 - val_acc: 0.8045\n",
      "5e-05  Epoch 112/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6987 - acc: 0.8362 - val_loss: 0.7145 - val_acc: 0.8086\n",
      "5e-05  Epoch 113/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.7023 - acc: 0.8327 - val_loss: 0.7425 - val_acc: 0.7819\n",
      "5e-05  Epoch 114/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6879 - acc: 0.8380 - val_loss: 0.7185 - val_acc: 0.7901\n",
      "5e-05  Epoch 115/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6834 - acc: 0.8405 - val_loss: 0.7052 - val_acc: 0.7922\n",
      "5e-05  Epoch 116/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6635 - acc: 0.8395 - val_loss: 0.6943 - val_acc: 0.8025\n",
      "5e-05  Epoch 117/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6541 - acc: 0.8468 - val_loss: 0.7075 - val_acc: 0.7942\n",
      "5e-05  Epoch 118/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6519 - acc: 0.8464 - val_loss: 0.6935 - val_acc: 0.8189\n",
      "5e-05  Epoch 119/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6405 - acc: 0.8464 - val_loss: 0.6832 - val_acc: 0.8086\n",
      "5e-05  Epoch 120/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6323 - acc: 0.8542 - val_loss: 0.6730 - val_acc: 0.8230\n",
      "5e-05  Epoch 121/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6267 - acc: 0.8522 - val_loss: 0.6744 - val_acc: 0.8066\n",
      "5e-05  Epoch 122/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224/9224 [==============================] - 3s - loss: 0.6210 - acc: 0.8557 - val_loss: 0.6867 - val_acc: 0.8004\n",
      "5e-05  Epoch 123/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6208 - acc: 0.8560 - val_loss: 0.6673 - val_acc: 0.8128\n",
      "5e-05  Epoch 124/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6130 - acc: 0.8570 - val_loss: 0.6746 - val_acc: 0.8066\n",
      "5e-05  Epoch 125/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6033 - acc: 0.8546 - val_loss: 0.6618 - val_acc: 0.8230\n",
      "5e-05  Epoch 126/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.6056 - acc: 0.8565 - val_loss: 0.6841 - val_acc: 0.7963\n",
      "5e-05  Epoch 127/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5973 - acc: 0.8620 - val_loss: 0.6885 - val_acc: 0.8107\n",
      "5e-05  Epoch 128/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5973 - acc: 0.8631 - val_loss: 0.6489 - val_acc: 0.8251\n",
      "5e-05  Epoch 129/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5950 - acc: 0.8594 - val_loss: 0.6346 - val_acc: 0.8313\n",
      "5e-05  Epoch 130/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5925 - acc: 0.8606 - val_loss: 0.6449 - val_acc: 0.8333\n",
      "5e-05  Epoch 131/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5782 - acc: 0.8638 - val_loss: 0.6664 - val_acc: 0.8148\n",
      "5e-05  Epoch 132/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5669 - acc: 0.8644 - val_loss: 0.6510 - val_acc: 0.8148\n",
      "5e-05  Epoch 133/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5786 - acc: 0.8624 - val_loss: 0.6720 - val_acc: 0.8066\n",
      "5e-05  Epoch 134/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5587 - acc: 0.8716 - val_loss: 0.6471 - val_acc: 0.8128\n",
      "5e-05  Epoch 135/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5448 - acc: 0.8760 - val_loss: 0.6263 - val_acc: 0.8374\n",
      "5e-05  Epoch 136/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5418 - acc: 0.8780 - val_loss: 0.6279 - val_acc: 0.8272\n",
      "5e-05  Epoch 137/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5288 - acc: 0.8778 - val_loss: 0.6276 - val_acc: 0.8210\n",
      "5e-05  Epoch 138/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5324 - acc: 0.8763 - val_loss: 0.6145 - val_acc: 0.8272\n",
      "5e-05  Epoch 139/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5165 - acc: 0.8816 - val_loss: 0.6149 - val_acc: 0.8230\n",
      "5e-05  Epoch 140/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5113 - acc: 0.8856 - val_loss: 0.6001 - val_acc: 0.8374\n",
      "5e-05  Epoch 141/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5042 - acc: 0.8828 - val_loss: 0.6069 - val_acc: 0.8354\n",
      "5e-05  Epoch 142/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5102 - acc: 0.8823 - val_loss: 0.6157 - val_acc: 0.8230\n",
      "5e-05  Epoch 143/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5077 - acc: 0.8856 - val_loss: 0.6223 - val_acc: 0.8272\n",
      "5e-05  Epoch 144/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5031 - acc: 0.8874 - val_loss: 0.6081 - val_acc: 0.8313\n",
      "5e-05  Epoch 145/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4853 - acc: 0.8890 - val_loss: 0.6133 - val_acc: 0.8272\n",
      "5e-05  Epoch 146/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4889 - acc: 0.8859 - val_loss: 0.6295 - val_acc: 0.8210\n",
      "5e-05  Epoch 147/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4831 - acc: 0.8873 - val_loss: 0.6020 - val_acc: 0.8313\n",
      "5e-05  Epoch 148/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4817 - acc: 0.8886 - val_loss: 0.6141 - val_acc: 0.8230\n",
      "5e-05  Epoch 149/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.5005 - acc: 0.8876 - val_loss: 0.6325 - val_acc: 0.8148\n",
      "5e-05  Epoch 150/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4828 - acc: 0.8895 - val_loss: 0.6089 - val_acc: 0.8210\n",
      "5e-05  Epoch 151/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4699 - acc: 0.8926 - val_loss: 0.5930 - val_acc: 0.8189\n",
      "5e-05  Epoch 152/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4650 - acc: 0.8935 - val_loss: 0.5862 - val_acc: 0.8292\n",
      "5e-05  Epoch 153/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4715 - acc: 0.8935 - val_loss: 0.6147 - val_acc: 0.8169\n",
      "5e-05  Epoch 154/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4673 - acc: 0.8948 - val_loss: 0.5888 - val_acc: 0.8292\n",
      "5e-05  Epoch 155/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4552 - acc: 0.9008 - val_loss: 0.5902 - val_acc: 0.8210\n",
      "5e-05  Epoch 156/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4672 - acc: 0.8938 - val_loss: 0.6223 - val_acc: 0.8210\n",
      "5e-05  Epoch 157/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4758 - acc: 0.8875 - val_loss: 0.6110 - val_acc: 0.8313\n",
      "5e-05  Epoch 158/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4572 - acc: 0.8957 - val_loss: 0.5949 - val_acc: 0.8272\n",
      "5e-05  Epoch 159/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4410 - acc: 0.9009 - val_loss: 0.5947 - val_acc: 0.8251\n",
      "5e-05  Epoch 160/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4450 - acc: 0.8987 - val_loss: 0.5962 - val_acc: 0.8169\n",
      "5e-05  Epoch 161/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4337 - acc: 0.9016 - val_loss: 0.5783 - val_acc: 0.8313\n",
      "5e-05  Epoch 162/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4185 - acc: 0.9054 - val_loss: 0.5787 - val_acc: 0.8354\n",
      "5e-05  Epoch 163/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4146 - acc: 0.9081 - val_loss: 0.5722 - val_acc: 0.8313\n",
      "5e-05  Epoch 164/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4047 - acc: 0.9125 - val_loss: 0.5562 - val_acc: 0.8498\n",
      "5e-05  Epoch 165/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4006 - acc: 0.9113 - val_loss: 0.5927 - val_acc: 0.8210\n",
      "5e-05  Epoch 166/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3987 - acc: 0.9131 - val_loss: 0.5528 - val_acc: 0.8416\n",
      "5e-05  Epoch 167/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4036 - acc: 0.9083 - val_loss: 0.5830 - val_acc: 0.8230\n",
      "5e-05  Epoch 168/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4009 - acc: 0.9093 - val_loss: 0.5642 - val_acc: 0.8477\n",
      "5e-05  Epoch 169/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3926 - acc: 0.9120 - val_loss: 0.5707 - val_acc: 0.8416\n",
      "5e-05  Epoch 170/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3866 - acc: 0.9101 - val_loss: 0.5551 - val_acc: 0.8395\n",
      "5e-05  Epoch 171/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3759 - acc: 0.9171 - val_loss: 0.5441 - val_acc: 0.8457\n",
      "5e-05  Epoch 172/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3774 - acc: 0.9148 - val_loss: 0.5533 - val_acc: 0.8313\n",
      "5e-05  Epoch 173/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3827 - acc: 0.9102 - val_loss: 0.5918 - val_acc: 0.8210\n",
      "5e-05  Epoch 174/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3805 - acc: 0.9127 - val_loss: 0.5886 - val_acc: 0.8251\n",
      "5e-05  Epoch 175/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3827 - acc: 0.9131 - val_loss: 0.5557 - val_acc: 0.8395\n",
      "5e-05  Epoch 176/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3795 - acc: 0.9137 - val_loss: 0.5581 - val_acc: 0.8395\n",
      "5e-05  Epoch 177/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3672 - acc: 0.9165 - val_loss: 0.5529 - val_acc: 0.8436\n",
      "5e-05  Epoch 178/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3586 - acc: 0.9235 - val_loss: 0.5754 - val_acc: 0.8148\n",
      "5e-05  Epoch 179/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.4243 - acc: 0.8974 - val_loss: 0.6595 - val_acc: 0.7963\n",
      "5e-05  Epoch 180/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3981 - acc: 0.9049 - val_loss: 0.5789 - val_acc: 0.8313\n",
      "5e-05  Epoch 181/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3729 - acc: 0.9149 - val_loss: 0.5650 - val_acc: 0.8374\n",
      "5e-05  Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9224/9224 [==============================] - 3s - loss: 0.3670 - acc: 0.9180 - val_loss: 0.5793 - val_acc: 0.8292\n",
      "5e-05  Epoch 183/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3664 - acc: 0.9194 - val_loss: 0.5625 - val_acc: 0.8354\n",
      "5e-05  Epoch 184/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3518 - acc: 0.9188 - val_loss: 0.5496 - val_acc: 0.8395\n",
      "5e-05  Epoch 185/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3571 - acc: 0.9175 - val_loss: 0.5773 - val_acc: 0.8230\n",
      "5e-05  Epoch 186/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3463 - acc: 0.9231 - val_loss: 0.5451 - val_acc: 0.8354\n",
      "5e-05  Epoch 187/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3460 - acc: 0.9247 - val_loss: 0.5677 - val_acc: 0.8395\n",
      "5e-05  Epoch 188/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3621 - acc: 0.9205 - val_loss: 0.5718 - val_acc: 0.8272\n",
      "5e-05  Epoch 189/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3613 - acc: 0.9213 - val_loss: 0.5727 - val_acc: 0.8292\n",
      "5e-05  Epoch 190/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3653 - acc: 0.9170 - val_loss: 0.6028 - val_acc: 0.8066\n",
      "5e-05  Epoch 191/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3431 - acc: 0.9225 - val_loss: 0.5482 - val_acc: 0.8272\n",
      "5e-05  Epoch 192/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3313 - acc: 0.9293 - val_loss: 0.5468 - val_acc: 0.8333\n",
      "5e-05  Epoch 193/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3244 - acc: 0.9291 - val_loss: 0.5656 - val_acc: 0.8333\n",
      "5e-05  Epoch 194/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3222 - acc: 0.9300 - val_loss: 0.5358 - val_acc: 0.8374\n",
      "5e-05  Epoch 195/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3098 - acc: 0.9309 - val_loss: 0.5431 - val_acc: 0.8292\n",
      "5e-05  Epoch 196/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3049 - acc: 0.9352 - val_loss: 0.5434 - val_acc: 0.8333\n",
      "5e-05  Epoch 197/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3032 - acc: 0.9342 - val_loss: 0.5361 - val_acc: 0.8354\n",
      "5e-05  Epoch 198/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.2990 - acc: 0.9359 - val_loss: 0.5425 - val_acc: 0.8354\n",
      "5e-05  Epoch 199/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.3014 - acc: 0.9337 - val_loss: 0.5247 - val_acc: 0.8457\n",
      "5e-05  Epoch 200/200\n",
      "9224/9224 [==============================] - 3s - loss: 0.2932 - acc: 0.9399 - val_loss: 0.5209 - val_acc: 0.8457\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=1024,\n",
    "                 epochs=200, #Increase this when not on Kaggle kernel\n",
    "                 verbose=1,  #1 for ETA, 0 for silent\n",
    "                 validation_data=(x_val, y_val), \n",
    "                 callbacks=[annealer,tensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486/486 [==============================] - 0s     \n",
      "Final loss: 0.5209, final accuracy: 0.8457\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_val, y_val, verbose=1)\n",
    "print(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_name_acc = run_name + '_' + str(int(final_acc*10000)).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['acc', 'loss', 'val_acc', 'val_loss', 'epoch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "histories = pd.DataFrame(hist.history)\n",
    "histories['epoch'] = hist.epoch\n",
    "print(histories.columns)\n",
    "histories_file = os.path.join(model_path, run_name_acc + '.csv')\n",
    "histories.to_csv(histories_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCm4RkRjz/xFz1f19F3bTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x67073fee80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhJTcRUSSkJK7iEgS+n9rJGN6YtDPpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x671a648ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist.history['loss'], color='b')\n",
    "plt.plot(hist.history['val_loss'], color='r')\n",
    "plt.show()\n",
    "plt.plot(hist.history['acc'], color='b')\n",
    "plt.plot(hist.history['val_acc'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveModel(model, run_name):\n",
    "    cwd = os.getcwd()\n",
    "    modelPath = os.path.join(cwd, 'model')\n",
    "    if not os.path.isdir(modelPath):\n",
    "        os.mkdir(modelPath)\n",
    "    weigthsFile = os.path.join(modelPath, run_name + '.h5')\n",
    "    model.save(weigthsFile)\n",
    "saveModel(model, run_name_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Used to load model directly and skip train\n",
    "# import os\n",
    "# from keras.models import load_model\n",
    "# cwd = os.getcwd()\n",
    "# model = load_model(os.path.join(cwd, 'model', 'Dog_Breed_Identification_Train_20171024_155154.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 120)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test, batch_size=128)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(y_pred[:10])\n",
    "# y_pred = np.clip(y_pred, 0.005, 0.995)\n",
    "# print(y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000621fb3cbb32d8935728e48679680e.jpg', '00102ee9d8eb90812350685311fe5890.jpg', '0012a730dfa437f5f3613fb75efcd4ce.jpg', '001510bc8570bbeee98c8d80c8a95ec1.jpg', '001a5f3114548acdefa3d4da05474c2e.jpg', '00225dcd3e4d2410dd53239f95c0352f.jpg', '002c2a3117c2193b4d26400ce431eebd.jpg', '002c58d413a521ae8d1a5daeb35fc803.jpg', '002f80396f1e3db687c5932d7978b196.jpg', '0036c6bcec6031be9e62a257b1c3c442.jpg']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(os.path.join(cwd, 'input', 'data_test', 'test'))\n",
    "print(files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lables amount: 10222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "df = pd.read_csv(os.path.join(cwd, 'input', 'labels.csv'))\n",
    "print('lables amount: %d' %len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'black-and-tan_coonhound', 'lakeland_terrier', 'schipperke', 'chow', 'bernese_mountain_dog', 'border_terrier', 'borzoi', 'boston_bull', 'kerry_blue_terrier', 'komondor', 'bloodhound', 'japanese_spaniel', 'saluki', 'standard_schnauzer', 'welsh_springer_spaniel', 'ibizan_hound', 'french_bulldog', 'collie', 'otterhound', 'irish_wolfhound', 'blenheim_spaniel', 'appenzeller', 'curly-coated_retriever', 'weimaraner', 'sussex_spaniel', 'siberian_husky', 'german_short-haired_pointer', 'irish_terrier', 'german_shepherd', 'wire-haired_fox_terrier', 'pomeranian', 'golden_retriever', 'shetland_sheepdog', 'scotch_terrier', 'irish_water_spaniel', 'australian_terrier', 'english_springer', 'labrador_retriever', 'staffordshire_bullterrier', 'brittany_spaniel', 'samoyed', 'rottweiler', 'norwich_terrier', 'dingo', 'mexican_hairless', 'bouvier_des_flandres', 'scottish_deerhound', 'toy_terrier', 'standard_poodle', 'old_english_sheepdog', 'bluetick', 'yorkshire_terrier', 'eskimo_dog', 'clumber', 'english_setter', 'west_highland_white_terrier', 'cocker_spaniel', 'dhole', 'leonberg', 'whippet', 'keeshond', 'bedlington_terrier', 'cairn', 'chihuahua', 'miniature_schnauzer', 'affenpinscher', 'tibetan_mastiff', 'pembroke', 'papillon', 'afghan_hound', 'silky_terrier', 'soft-coated_wheaten_terrier', 'saint_bernard', 'toy_poodle', 'cardigan', 'walker_hound', 'redbone', 'kuvasz', 'newfoundland', 'vizsla', 'greater_swiss_mountain_dog', 'maltese_dog', 'lhasa', 'basset', 'norwegian_elkhound', 'giant_schnauzer', 'dandie_dinmont', 'basenji', 'sealyham_terrier', 'norfolk_terrier', 'great_pyrenees', 'american_staffordshire_terrier', 'beagle', 'pekinese', 'border_collie', 'flat-coated_retriever', 'english_foxhound', 'airedale', 'african_hunting_dog', 'groenendael', 'tibetan_terrier', 'pug', 'briard', 'miniature_pinscher', 'rhodesian_ridgeback', 'entlebucher', 'malinois', 'irish_setter', 'brabancon_griffon', 'shih-tzu', 'malamute', 'great_dane', 'italian_greyhound', 'chesapeake_bay_retriever', 'boxer', 'doberman', 'bull_mastiff', 'kelpie', 'gordon_setter', 'miniature_poodle'}\n"
     ]
    }
   ],
   "source": [
    "n = len(df)\n",
    "breed = set(df['breed'])\n",
    "n_class = len(breed)\n",
    "class_to_num = dict(zip(breed, range(n_class)))\n",
    "num_to_class = dict(zip(range(n_class), breed))\n",
    "print(breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 121)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('.\\\\input\\\\sample_submission.csv')\n",
    "n_test = len(df2)\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, 120):\n",
    "    df2.iloc[:,[i+1]] = y_pred[:,i]\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "pred_file = os.path.join(output_path, 'pred_' + run_name_acc + '.csv')\n",
    "df2.to_csv(pred_file, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog_Breed_Identification_Train-Predict_20171111_230804_8456\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print(run_name_acc)\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
