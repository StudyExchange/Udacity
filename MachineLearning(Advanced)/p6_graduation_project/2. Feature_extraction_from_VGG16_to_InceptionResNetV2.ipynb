{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. 特征提取_从VGG16到InceptionResNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "1. https://github.com/ypwhs/dogs_vs_cats\n",
    "2. https://www.kaggle.com/yangpeiwen/keras-inception-xception-0-47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用预训练权重的VGG16、VGG19、ResNet50、Xception和InceptionV3模型提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(MODEL, image_size, date_str, lambda_func=None, batch_size=1):\n",
    "    print('{0} start.'.format(MODEL.__name__))\n",
    "    start_time = time.time()\n",
    "    \n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        print(lambda_func.__name__)\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', input_shape=(height, width, 3), include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    data_train_path = os.path.join(cwd, 'input', 'data_train')\n",
    "    data_val_path = os.path.join(cwd, 'input', 'data_val')\n",
    "    data_test_path  = os.path.join(cwd, 'input', 'data_test')\n",
    "    \n",
    "    gen = ImageDataGenerator()\n",
    "#     gen = ImageDataGenerator(zoom_range = 0.1,\n",
    "#                             height_shift_range = 0.1,\n",
    "#                             width_shift_range = 0.1,\n",
    "#                             rotation_range = 10)\n",
    "    train_generator = gen.flow_from_directory(data_train_path, image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    val_generator = gen.flow_from_directory(data_val_path, image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    test_generator  = gen.flow_from_directory(data_test_path,  image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    \n",
    "    print(len(train_generator.filenames))\n",
    "    print(len(test_generator.filenames))\n",
    "    print('train_generator')\n",
    "    train = model.predict_generator(train_generator, verbose=1, steps=len(train_generator.filenames))\n",
    "    print('val_generator')\n",
    "    val = model.predict_generator(val_generator, verbose=1, steps=len(val_generator.filenames))\n",
    "    print('test_generator')\n",
    "    test = model.predict_generator(test_generator, verbose=1, steps=len(test_generator.filenames))\n",
    "    \n",
    "#     print('train_generator')\n",
    "#     train = model.predict_generator(train_generator, verbose=1, steps=10)\n",
    "#     print('test_generator')\n",
    "#     test = model.predict_generator(test_generator, verbose=1, steps=10)\n",
    "\n",
    "    folder_path = os.path.join(cwd, 'model')\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    file_name = os.path.join(cwd, 'model', 'feature_{0}_{1}.h5'.format(MODEL.__name__, date_str))\n",
    "    print(file_name)\n",
    "    if os.path.exists(file_name):\n",
    "        os.remove(file_name)\n",
    "        \n",
    "    with h5py.File(file_name) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"train_labels\", data=train_generator.classes)\n",
    "        h.create_dataset(\"val\", data=val)\n",
    "        h.create_dataset(\"val_labels\", data=val_generator.classes)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "    \n",
    "    print(train.shape)\n",
    "    print(train_generator.classes)\n",
    "    print(test.shape)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print('Spend time: {0} s'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180223\n"
     ]
    }
   ],
   "source": [
    "# Get date str\n",
    "# date_str = time.strftime(\"%Y%m%d\", time.localtime())\n",
    "date_str = '20180223'\n",
    "print(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_features(VGG16, (224, 224), date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_features(VGG19, (224, 224), date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_features(ResNet50, (224, 224), date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_features(MobileNet, (224, 224), date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xception start.\n",
      "preprocess_input\n",
      "Found 9710 images belonging to 120 classes.\n",
      "Found 512 images belonging to 120 classes.\n",
      "Found 10357 images belonging to 1 classes.\n",
      "9710\n",
      "10357\n",
      "train_generator\n",
      "9710/9710 [==============================] - 1639s 169ms/step\n",
      "val_generator\n",
      "512/512 [==============================] - 87s 169ms/step\n",
      "test_generator\n",
      "10357/10357 [==============================] - 1749s 169ms/step\n",
      "D:\\Udacity\\MachineLearning(Advanced)\\p6_graduation_project\\model\\feature_Xception_20180223.h5\n",
      "(9710, 2048)\n",
      "[  0   0   0 ..., 119 119 119]\n",
      "(10357, 2048)\n",
      "Spend time: 3485.1917214393616 s\n"
     ]
    }
   ],
   "source": [
    "get_features(Xception, (299, 299), date_str, xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 start.\n",
      "preprocess_input\n",
      "Found 9710 images belonging to 120 classes.\n",
      "Found 512 images belonging to 120 classes.\n",
      "Found 10357 images belonging to 1 classes.\n",
      "9710\n",
      "10357\n",
      "train_generator\n",
      "9710/9710 [==============================] - 1576s 162ms/step\n",
      "val_generator\n",
      "512/512 [==============================] - 83s 162ms/step\n",
      "test_generator\n",
      "10357/10357 [==============================] - 1695s 164ms/step\n",
      "D:\\Udacity\\MachineLearning(Advanced)\\p6_graduation_project\\model\\feature_InceptionV3_20180223.h5\n",
      "(9710, 2048)\n",
      "[  0   0   0 ..., 119 119 119]\n",
      "(10357, 2048)\n",
      "Spend time: 3372.2834899425507 s\n"
     ]
    }
   ],
   "source": [
    "get_features(InceptionV3, (299, 299), date_str, inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionResNetV2 start.\n",
      "preprocess_input\n",
      "Found 9710 images belonging to 120 classes.\n",
      "Found 512 images belonging to 120 classes.\n",
      "Found 10357 images belonging to 1 classes.\n",
      "9710\n",
      "10357\n",
      "train_generator\n",
      "9710/9710 [==============================] - 2808s 289ms/step\n",
      "val_generator\n",
      "512/512 [==============================] - 147s 288ms/step\n",
      "test_generator\n",
      "10357/10357 [==============================] - 2985s 288ms/step\n",
      "D:\\Udacity\\MachineLearning(Advanced)\\p6_graduation_project\\model\\feature_InceptionResNetV2_20180223.h5\n",
      "(9710, 1536)\n",
      "[  0   0   0 ..., 119 119 119]\n",
      "(10357, 1536)\n",
      "Spend time: 5973.684639215469 s\n"
     ]
    }
   ],
   "source": [
    "get_features(InceptionResNetV2, (299, 299), date_str, inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
